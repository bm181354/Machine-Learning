Description:

The second assignment from the week three of coursera's stanford Machine learning course.

In this assignment, Prof.Andrew Ng discusses about logistical regression and regularization of these regression to negate any kind of wrong approximation--overfitting and under-fitting.

Scores:
 
==  Part Name |     Score | Feedback.
== --------- |     ----- | --------
== Sigmoid Function |   5 /   5 | Nice work!.
== Logistic Regression Cost |  30 /  30 | Nice work!.
== Logistic Regression Gradient |  30 /  30 | Nice work!.
== Predict |   5 /   5 | Nice work!.
== Regularized Logistic Regression Cost |  15 /  15 | Nice work!.
== Regularized Logistic Regression Gradient |  15 /  15 | Nice work!.
== ————————————————.
== | 100 / 100 | . 